var tipuesearch = {"pages":[{"title":"Patching with unittest.mock for Python testing: cheat sheet","text":"Overview of patching Python built-in unittest framework provides the mock module which gets very handy when writing unit tests. It also provides the patch entity which can be used as a function decorator, class decorator or a context manager. The basic idea behind patching is that it lets you temporarily change the object that is being used when your test runs. For example, if you are testing a function that needs to read some data out of a database, you can patch it so that you don't need to communicate with any external services when unit tests run. Given this piece of code, we are interested in testing the get_customers() function. We have tests in place for functions ( validate_input and fetch ) that this function calls, so that we can ignore them. def get_customers ( city : str ): validate_input ( object_type = CITY , value = city ) customers = fetch ( query = f 'customers;city= { city } ' ) return customers To patch those functions, instead of calling them at the execution time, anonymous lambda functions could be used. For the validate_input() function, we are not interested in the return value; however, for the fetch function we are. from unittest.mock import patch from utils import get_customers @patch ( 'utils.validate_input' , lambda object_type , value : None ) def test_get_customers (): expected_customers = [ 'Customer1' , 'Customer2' ] with patch ( 'utils.fetch' , lambda query : expected_customers ): actual_customers = get_customers ( city = 'Paris' ) assert actual_customers == expected_customers The patched fetch function doesn't have to return any meaningful value as we will only be testing whether it returned what the patching function is supposed to return. However, I often find it to be easier to understand the context and business logic when some more real values are used. Note that the patch() was used both as a context manager and as a test function decorator. In the rest of the post, we will explore typical use cases for patching and mocking. Patching class initialization Use case: You want to test a class method, but initializing a class instance would require a lot of additional mocking to pass valid input parameters. You also want to avoid any real initialization operations, but would still want to have some of the class instance variables set. Code: class FileProcessor : def __init__ ( self , files : List [ Path ], process_config : ProcessorConfiguration ): self . files = files self . process_config = process_config def validate_files ( self ): # operate on the files and return some validation result ... Test: def test_validate_files (): with patch . object ( FileProcessor , '__init__' , lambda self : None ): fp = FileProcessor () fp . files = [ Path ( 'foo' ), Path ( 'bar' )] assert fp . validate_files () . get ( \"status\" ) == ValidationStatus . SUCCESS fp . files = [] assert fp . validate_files () . get ( \"status\" ) == ValidationStatus . FAILURE Patching static, class, and instance methods Use case: You have a class for which you want to patch some of the class instance methods, class methods, or static methods. You would need to patch a method of interest and the process of patching the methods is universal for all the methods types. Code: class Address : def __init__ ( self , house : str , street : str , postal_code : str , city : str ): self . house = Address . numerize ( house ) self . street = street self . postal_code = postal_code self . city = city @classmethod def from_tuple ( cls , * address_tuple : Tuple ): return Address ( * address_tuple ) @staticmethod def numerize ( value ): return int ( value ) def to_string ( self ): return f \" { self . house }{ self . street } \\n { self . postal_code } \\n { self . city } \" def print ( self ): fmt = self . to_string () print ( fmt ) return fmt def is_valid_address ( address_tuple ): try : Address . from_tuple ( * address_tuple ) return True except Exception : return False Test: def test_is_valid_address (): with patch ( 'static_class.Address.from_tuple' , lambda * data : True ): assert is_valid_address (( \"1\" , \"New Road\" , \"99999\" , \"City\" )) with patch ( 'static_class.Address.from_tuple' , side_effect = Exception ()): assert not is_valid_address (( \"1\" , \"New Road\" , \"99999\" , \"City\" )) def test_address_construct (): with patch ( 'static_class.Address.numerize' , lambda value : 9999 ): address = Address ( * ( \"1\" , \"New Road\" , \"99999\" , \"City\" )) assert address . city == \"City\" assert address . house == 9999 def test_print (): with patch ( 'static_class.Address.to_string' , lambda value : \"Address formatted\" ): address = Address ( * ( \"1\" , \"New Road\" , \"99999\" , \"City\" )) assert address . print () == \"Address formatted\" Patching multiple calls to the same function Use case: You call a function being mocked multiple times in the source code being tested and need to return a different value for each call. For instance, you mock a function call that will check whether a database table exists, then you call a function to delete it, and then use the first function again to make sure that the table does not exist (i.e., it was successfully deleted). You cannot simply mock the function with the patch because it will then return the same value. You have to use the Mock().side_effect property. The side_effect collection can even have an exception initialization if at a certain time you call the mocked function a particular exception is expected to be raised: side_effect = [10, 15, ValueError()] . Code: def get_table ( name ): return True def delete_table ( name ): return True def delete_db_table ( table_name : str ) -> bool : if get_table ( table_name ): delete_table ( table_name ) if not get_table ( table_name ): return True else : raise ValueError ( f \"Failed to delete table { table_name } \" ) return True Test: @patch ( 'db.delete_table' , lambda name : True ) def test_delete_db_table (): get_table_mock = Mock () # db table gets deleted get_table_mock . side_effect = [ True , False ] with patch ( 'db.get_table' , get_table_mock ): assert delete_db_table ( \"LogHistory\" ) # db table fails to be deleted get_table_mock . side_effect = [ True , True ] with patch ( 'db.get_table' , get_table_mock ): with pytest . raises ( ValueError ): delete_db_table ( \"LogHistory\" ) Patching function and its returned object Use case: When you patch a function or a method, it may be the case that the object that it will return may have own methods that you would want to patch. For instance, when patching subprocess.run() that returns a CompletedProcess object, you may want to patch its .check_returncode() method to return some value. Just as with the Mock().side_effect() , it's possible to create side effects for methods of a Mock() object. Code: def call_cmd ( cmd : str ): res = subprocess . run ( cmd ) return res . check_returncode () Test: def test_call_cmd (): run_mock = Mock () run_mock . check_returncode . return_value = \"0\" with patch ( 'subprocess_run.subprocess.run' , lambda cmd : run_mock ): assert call_cmd ( 'du -sh lib' ) == \"0\" run_mock = Mock () run_mock . check_returncode . side_effect = subprocess . CalledProcessError ( 0 , 0 ) with patch ( 'subprocess_run.subprocess.run' , lambda cmd : run_mock ): with pytest . raises ( CalledProcessError ): call_cmd ( 'du -sh non-existing-dir' ) Patching class properties Use case: You have a class with one or more properties decorated with the @property . Mocking them requires special handling using the unittest.mock.PropertyMock object. This is useful when the initialization of an object's property is complex and is not really required for a particular unit test. Code: class Process : def __init__ ( self , pid : int ): self . _pid = pid @property def pid ( self ): return self . _pid def as_string ( self ): return f 'Process( { self . pid } )' Test: def test_process_pid_property (): with patch . object ( Process , '__init__' , lambda self : None ): with patch ( 'class_properties.Process.pid' , new_callable = PropertyMock ) as mock_pid : mock_pid . return_value = 99 process = Process () assert process . as_string () == 'Process(99)' Patching opening a file with open Use case: You have a function that is interacting with the file system by opening a file. A helper function unittest.mock.mock_open can be used to replace the use of open . Code: def read ( path ): with open ( path ) as f : return f . readlines () Test: def test_read_file (): with patch ( 'read_file.open' , mock_open ( read_data = \"lines\" )): assert read ( 'dir/path' ) == [ \"lines\" ] Notes When mocking is required for too many places, it may be the case that your class or a function is too big and would be a good candidate for refactoring. To make mocking for a large (or complex) code unit easier, you can use unittest.mock.MagicMock() instead. When patching code that is interacting with the file system too often, patching all the os , pathlib , and shutil things can get tedious rather quickly. You may want to take a look at the virtual file system, pyfakefs , to be used when testing. Keep in mind that you won't be able to use mock.patch to patch your file system interaction functions when you use pyfakefs because it patches them on its own. When your programs are really scripts that process some files, you may be better off writing good integration tests using real data instead. This could be particularly true when your Python program is relying on using non-Python code such as compiled C (for which you have no source code) to read/process/write data. In this situation, you won't be able to use the pyfakefs virtual file system and mocking all the interaction between your Python programs and external tools can be tedious. If the programs for which you write unit tests interact with external web services over HTTP a lot, you may look into the vcrpy package that can automatically mock your HTTP interactions. The pytest-recording plugin provides handy custom markers. Happy patching!","tags":"python","url":"/patching-mock-python-unit-testing.html","loc":"/patching-mock-python-unit-testing.html"},{"title":"Working with stdout in Python scripts","text":"Overview When working with an existing Python script, particularly a legacy script, or a script that was supposed to be used once and then thrown away but grew into a business critical application (yep, this happens), it can be common to see extensive usage of print or logging statements. Those statements can be spread across the program code and often provide useful information regarding the status of the process while the script is being executed. However, if you have been writing a new script and have finished working on it, or if the script output is not of interest any longer, you most likely wouldn't want to clutter the Python console with print / logging outputs (particularly if the script is part of another larger pipeline). However, the information emitted can still be useful to get logged. Redirecting to a file Instead of removing each print statement (or switching to logging.debug from logging.info ), it is possible to specify to what file the sys.stdout will redirect writing to. This will make the print and logging calls to write to a file on disk instead. import sys # keeping the original reference to the output destination stdout = sys . stdout print ( \"Started script\" ) # redirecting the print statements to the file f = open ( 'log.txt' , 'a' ) sys . stdout = f # main program execution, gets logged to a file print ( \"Getting work done\" ) # setting it to the original output destination sys . stdout = stdout f . close () print ( \"Finished script\" ) Now, when running the program, the print() calls within the main program logic are being redirected to a file on disk. $ python3 program_print.py Started script Finished script $ cat log.txt Getting work done Redirecting to StringIO It is also possible to use the io.StringIO() object to capture everything that will be written to the stdout for the whole script or only a portion of it. import sys from io import StringIO print ( \"Started script\" ) # to capture anything that will be written to the stdout buf = StringIO () stdout = sys . stdout sys . stdout = buf print ( 'Getting work done' ) sys . stdout = stdout # collecting what has been written into a variable captured = buf . getvalue () print ( \"Finished script \\n \" ) print ( captured ) Now, when running the program, the print() calls within the main program logic are being collected into a variable (which is printed here for examination, but can be used for any custom logging). $ python3 program_stringio_var.py Started script Finished script Getting work done Overriding the sys.stdout.write method In both of the examples above, the text that was sent to the original stdout wasn't shown in the console (it's either simply suppressed or captured into a variable). However, it can be sometimes useful to print the output both to the console and put the output into a variable. For this use case, we are essentially after what the tee command does in Linux (which can read stdin and then write it to both the stdout and to a file). In Python, this can be achieved by overriding the sys.stdout.write method. import sys from io import StringIO class StdOutTee : def __init__ ( self , * authors ): self . authors = authors def write ( self , text ): for author in self . authors : author . write ( text ) print ( \"Started script\" ) # to capture anything that will be written to the stdout buf = StringIO () stdout = sys . stdout sys . stdout = StdOutTee ( buf , stdout ) print ( 'Getting work done 1' ) print ( 'Getting work done 2' ) sys . stdout = stdout # collecting what has been written into a variable captured = buf . getvalue () print ( \"Finished script \\n \" ) print ( captured ) Now, when running the program, the print() calls within the main program logic are being collected into a variable (which is printed here for examination, but can be used for any custom logging). However, all the print() statements are printed as well. $ python3 program_tee.py Started script Getting work done 1 Getting work done 2 Finished script Getting work done 1 Getting work done 2 Happy printing!","tags":"python","url":"/working-with-stdout-python.html","loc":"/working-with-stdout-python.html"},{"title":"Building cli Python applications with Click","text":"Overview When writing cli tools using Python, if the complexity is low, using a plain argparse may suffice. Despite being a built-in module, it's still very capable and relatively flexible. In fact, a few large open-source projects have survived using argparse without using any custom cli frameworks. For instance, Conan – a popular C/C++ package manager written in Python – and Google API Client for Python – Google's discovery based APIs – are using argparse for their cli interfaces. When argparse limitations get in the way, you may start looking for Python frameworks that allow developing cli applications . There is a post with practical demonstrations of most popular Python cli frameworks that is worth reviewing: Building Beautiful Command Line Interfaces with Python . Building a cli with Click My personal preference for a Python cli framework is Click . It has the functionality I want to have when building cli applications and whenever I needed something a bit peculiar, I was able to find the answers online thanks to posts of Stephen Rauch . To save time for others, I've created a boilerplate repository – click-cli-boilerplate – that contains everything that one would need to get started developing a cli application using Click . It features the Python project source code layout, cli interface and implementation relation, tests, packaging, and docs generation. You will find some brief notes on how to write tests, how to generate the docs using the sphinx-click extension, and how to distribute the cli application as a Python wheel and let users install it with the pipx . Happy cli-ing!","tags":"python","url":"/building-cli-python-apps-with-click.html","loc":"/building-cli-python-apps-with-click.html"},{"title":"Brief overview of using Git LFS for managing binary files","text":"Overview Normally a Git repository is used to manage source code which is stored most often as plain text. Tracking changes for text is very easy because only the changes between two commits would need to be saved, not the whole copies of the files. However, a project source code repository may also contain binary files such as images, compiled code, or archives. Developers from quite a few industries such as gaming or computer-aided design and digital mapping (e.g. textures, CAD drawings, and map style files) often have to manage and store large files. Having files of a few megabytes or hundreds of megabytes in size can be very common in the project source code repository, however, there is nothing wrong with having them there since this is where they really belong. Problem of keeping binary files under Git Because Git cannot track changes between binary files, for each modification of a binary file, a copy of the modified file will be created and stored. This can make the repository unnecessary large and slow to clone and check out. Always overwriting the binary file with the latest file state (to keep only the \"latest\") defeats the purpose of the source code management as one should be able to have access to the history even if it implies storing a hundred of binary files each differing from others by just a few bytes. What is a large file is a subject for discussion. I'd also encourage to think about how often a binary file will change; if it's a couple of megabytes static image used in a background of your terminal app, you may be fine just storing it as is. If it's a dynamic file that will be modified daily by multiple developers, just half a megabyte digital drawing file can bloat the repository for all of time if it's modified often. Having many tiny binary files that are changed often can have a similar effect. Using Git LFS for tracking binary files A more efficient way to store the binary files is to store them not under the Git repository (when a change to a binary file will cause creating its full copy), but in a separate storage system such as Git LFS . This system lets you store in the Git repository only the pointers to versions of the binary files, whereas the files themselves are stored separately. When cloning the repository with the latest master , you will only need to download the latest file, not its whole history. When checking out a feature-branch (that may have another representation of the very same file), another file version will be downloaded. Most of the major source code management providers such as GitHub, GitLab, and BitBucket provide support for Git LFS and enabling it is extremely easy. To learn more about Git LFS and support for large objects in Git, see the excellent video Native Git support for large objects from the Git Merge 2019. Migration of files to LFS The decisions about management of the binary files should be made as early as possible when setting up the repository. This is because it's a lot easier to start using Git LFS when a new repository is created rather than when binary files have already sneaked into the Git history. Ideally, you shouldn't be tracking with Git binary files that are supposed to be modified often. If the files did sneak into the Git history, simply removing the files and then starting storing them in a separate LFS system won't be enough as the Git repository will still have copies of those binary files in the history (in the .git directory). It is possible to remove them completely, but this would require \"rewriting\" the history and would require careful coordination with anyone else using the repository to run a few git rebase --onto sessions. For a repository with a few branches used by a few developers this won't be a problem, but it can become impractical and plain tedious to migrate the files for a large repository with many contributors and many branches. If you do need to move the files out of a \"regular\" Git to the LFS system, refer to the Migrating existing repository data to LFS page section in the Git LFS tutorial. Happy storing!","tags":"git","url":"/overview-using-git-lfs-binary-files.html","loc":"/overview-using-git-lfs-binary-files.html"},{"title":"Running Python tests with tox in a Docker container","text":"Overview When you are working on Python code that is supposed to be running on Python interpreters of multiple versions (and potentially with multiple versions of 3rd party packages), to be able to test that your code works and produces expected result you would need to create isolated virtual environments. Each of these virtual environments will have a certain version of Python and a certain version of each 3rd party package that your programs depend on. By having just a few versions of Python with a couple of versions of a few packages, it becomes rather tedious to create and maintain those virtual environments manually very soon. tox is a tool that can help you with this. Preparing Python virtual environments It is possible to create Python virtual environments manually and then let tox use them, however, you would most likely want tox to generate those virtual environments for you. For tox to use Python interpreters of multiple versions, they have to be installed on your machine. Even though this is possible, it may still be less optimal given that you will most likely need to make system changes (install a system package on Linux, use homebrew on MacOS, or download a Python app or an installer on Windows). Fortunately, tox can be run in a Docker container which will help to prevent cluttering your system. Running tests with tox in Docker: simple configuration To be able to run Python tests with tox in a Docker container, you will need a Dockerfile. FROM ubuntu:18.04 RUN apt-get -qq update RUN apt-get install -y --no-install-recommends \\ python3.7 python3.7-distutils python3.7-dev \\ python3.8 python3.8-distutils python3.8-dev \\ wget \\ ca-certificates RUN wget https://bootstrap.pypa.io/get-pip.py \\ && python3 get-pip.py pip == 19 .1.1 \\ && rm get-pip.py RUN python3.6 --version RUN python3.7 --version RUN python3.8 --version RUN pip3 install tox pytest The tox.ini file where you specify the Python environments. [tox] envlist = py36,py37,py38 skipsdist = True [testenv] deps = pytest commands = pytest The test_module.py containing a simple test function. def test_foo (): assert 2 + 3 == 5 Now you can build an image and then run the tests. $ docker build -t snake . $ docker run -it -v ${ PWD } /:/app snake /bin/sh -c 'cd app; tox' The pytest output will be printed for each of the Python environments in which the tests have been run (posted below with some sections removed for brevity). using tox . ini : / app / tox . ini ( pid 7 ) ... [ 16 ] / app$ / app / . tox / py36 / bin / pytest ================================================= test session starts ================================================= platform linux -- Python 3.6.9, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py36 / . pytest_cache rootdir : / app collected 1 item test_module . py . [ 100 % ] ================================================== 1 passed in 0 . 01 s ================================================== ... [ 21 ] / app$ / app / . tox / py37 / bin / pytest ================================================= test session starts ================================================= platform linux -- Python 3.7.5, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py37 / . pytest_cache rootdir : / app collected 1 item test_module . py . [ 100 % ] ================================================== 1 passed in 0 . 01 s ================================================== ... [ 26 ] / app$ / app / . tox / py38 / bin / pytest ================================================= test session starts ================================================= platform linux -- Python 3.8.0, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py38 / . pytest_cache rootdir : / app collected 1 item test_module . py . [ 100 % ] ================================================== 1 passed in 0 . 01 s ================================================== _______________________________________________________ summary _______________________________________________________ py36 : commands succeeded py37 : commands succeeded py38 : commands succeeded congratulations :) Running tests with tox in Docker: advanced configuration For a more complex use case, for instance, when you are working on a library that depends on some 3rd Python package, say, pandas , you can specify which versions of pandas you'd like to test your project's code with. For the example below, your tests will be run in 6 different environments. The tox.ini configuration file. [tox] envlist = py36-pandas{112,113}, py37-pandas{112,113}, py38-pandas{112,113} skipsdist = True [testenv] deps = pandas112: pandas==1.1.2 pandas113: pandas==1.1.3 pytest commands = pytest The test_pandas.py containing a simple test function to create two data frames and compare them. import pandas as pd from pandas._testing import assert_frame_equal def test_pandas (): df1 = pd . DataFrame ({ 'a' : [ 1 , 2 ], 'b' : [ 3 , 4 ]}) df2 = pd . DataFrame ({ 'a' : [ 1 , 2 ], 'b' : [ 3 , 4 ]}) assert_frame_equal ( df1 , df2 ) The pytest output will be printed for each of the Python environments in which the tests have been run (posted below with some sections removed for brevity). [ 52 ] / app$ / app / . tox / py36 - pandas112 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.6.9, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py36 - pandas112 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 63 s ==================================================================== [ 73 ] / app$ / app / . tox / py36 - pandas113 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.6.9, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py36 - pandas113 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 47 s ==================================================================== [ 115 ] / app$ / app / . tox / py37 - pandas112 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.7.5, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py37 - pandas112 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 51 s ==================================================================== [ 133 ] / app$ / app / . tox / py37 - pandas113 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.7.5, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py37 - pandas113 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 42 s ==================================================================== [ 174 ] / app$ / app / . tox / py38 - pandas112 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.8.0, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py38 - pandas112 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 48 s ==================================================================== [ 193 ] / app$ / app / . tox / py38 - pandas113 / bin / pytest =================================================================== test session starts =================================================================== platform linux -- Python 3.8.0, pytest-6.1.2, py-1.9.0, pluggy-0.13.1 cachedir : . tox / py38 - pandas113 / . pytest_cache rootdir : / app collected 2 items test_module . py . [ 50 % ] test_pandas . py . [ 100 % ] ==================================================================== 2 passed in 0 . 38 s ==================================================================== _________________________________________________________________________ summary _________________________________________________________________________ py36 - pandas112 : commands succeeded py36 - pandas113 : commands succeeded py37 - pandas112 : commands succeeded py37 - pandas113 : commands succeeded py38 - pandas112 : commands succeeded py38 - pandas113 : commands succeeded congratulations :) There are quite a few resources online that go deeper into how one can use tox in a Docker container, but this simple layout has been very useful to me in various circumstances and may help others. Happy testing!","tags":"python","url":"/run-python-tests-with-tox-in-docker.html","loc":"/run-python-tests-with-tox-in-docker.html"},{"title":"Using Docker for Python development: cheat sheet","text":"The Docker framework can be an extremely useful tool for any Python developer who wants to run their Python programs (either for development or testing purposes) in a certain isolated environment with a pre-defined set of system and Python packages installed. Docker can also help with testing your Python code against multiple versions of the Python packages in multiple operating systems. The beauty of Docker is that you don't need to understand the intricate details of how Docker technology works to take advantage of it. This blog post contains recipes any Python developer can benefit from regardless how experienced you are with Docker and containerization techniques. Each recipe or scenario is based on a problem that one may need to solve and provides a solution in form of a Dockerfile file, a docker build , and a docker run command. Basic setup The base Docker image you'll be using will likely to be different depending on a number of factors, however, to keep the build time short, I'll be using the alpine image in most cases. Dockerfile contents: FROM python:3.7-alpine CMD [ \"python3\" , \"--version\" ] The build step contains the -t flag which defines the tag name of the image that will be built. The dot ( . ) tells Docker to use the the file named Dockerfile in the current directory. Building a Docker image: $ docker build -t snake . When an image is run, the CMD command found in the Dockerfile is executed. The --rm (remove) flag will make sure to delete the container once the run command is complete. Running a Docker image: $ docker run --rm snake # Python 3.7.9 Experiment with a Python REPL of any version FROM python:3.7.8-alpine CMD [ \"python3\" ] By changing the version, you can get into an interactive Python console for the given version. This is very handy when you want to test how a certain feature works in a newer or an older Python version. When a docker run command is executed, it will run the CMD command and exit, so you won't be able to interact with the REPL. To work with the container in an interactive mode, the -it flag should be used. $ docker run --rm -it snake # Python REPL becomes available Passing a command to a Python Docker image FROM python:3.7.8-alpine When running a Docker container, it's possible to pass a command, optionally, with additional arguments. Python provides support for running a command with the -c option so that it's possible to supply the program code as a string. This can be very handy when you need to have a one-liner for an operation that will return a value you may need later as input for the subsequent operations. $ docker run --rm -it snake python3 --version # Python 3.7.8 $ docker run --rm -it snake python3 -c \"import sys; print(sys.platform)\" # linux Run a Python program from the host in a Docker container FROM python:3.7.8-alpine It is possible to mount a local directory (on your disk) as a volume to a Docker container which is done with the -v parameter. Running the command below will make the app directory files available in the Docker container. This approach can be used when you want to run a Python program in a Docker container likely having a different system environment and Python version installed. Having this Python program (stored at app/main.py ): import sys print ( sys . version_info ) you can execute it with: $ docker run -v ${ PWD } /app:/app snake python3 /app/main.py # sys.version_info(major=3, minor=7, micro=8, releaselevel='final', serial=0) It is also possible to copy files to the Docker image when the image is being built if you don't want to mount any volumes at the run time. FROM python:3.7.8-alpine WORKDIR /opt/project/app COPY ./app CMD [ \"python3\" , \"main.py\" ] You can now run the Docker container to execute the main.py file that was copied: $ docker run --rm snake # sys.version_info(major=3, minor=7, micro=8, releaselevel='final', serial=0) Alternatively, you could also make the CMD command a part of the docker run : FROM python:3.7.8-alpine WORKDIR /opt/project/app COPY ./app Then you pass the arguments to the container from the shell instead: $ docker run --rm snake python3 main.py # sys.version_info(major=3, minor=7, micro=8, releaselevel='final', serial=0) Get into a Docker container shell and run a command FROM python:3.7.8-alpine WORKDIR /opt/project/app COPY ./app . It is possible to start a Docker container and run a shell console to execute arbitrary commands. This resembles connecting to a remote machine via an SSH connection or using a local Bash console. $ docker run --rm -it snake /bin/sh # /opt/project/app # ls # main.py # /opt/project/app # python3 main.py # sys.version_info(major=3, minor=7, micro=8, releaselevel='final', serial=0) Access files created in the Docker container on the host Accessing files that are created by processes run in a Docker container is possible by mounting a volume. FROM python:3.7.8-alpine WORKDIR /opt/project/app Now you can run the container in the interactive mode and attach a shell console: $ docker run -it -v ${ PWD } /app:/opt/project/app snake /bin/sh # > touch foo.bar The foo.bar file will appear on your host disk under the app directory. This makes it possible to create arbitrary files within your Docker container saving them on your host disk making them accessible for further usage locally. Copy files produced by Docker build command to the host In certain cases, a Dockerfile may create new files which can be accessed when starting the container. FROM alpine RUN echo \"some data\" > /home/data.out The trick here is to mount your host's directory to some other directory than container's home and then copy the file(s) you need to this intermediate location. $ docker run --rm -it -v ${ PWD } /datadir:/home/datadir snake # cp /home/data.out /home/datadir/ At this point, the data.out file should appear on your host's disk under the datadir directory in your current working directory. Run Python tests stored on your host inside a Docker container To do this, one would need to have a Docker container with the pip installed and the necessary Python packages that are required by your tests. It can be wise to install a tested version of pip to avoid getting the latest one in case it's broken (this has happened before a few times). FROM python:3.7.8-alpine RUN wget -q https://bootstrap.pypa.io/get-pip.py \\ && python3 get-pip.py pip == 19 .1.1 \\ && rm get-pip.py COPY app/requirements.txt ./ RUN pip install -q --no-cache-dir \\ -r requirements.txt \\ && rm requirements.txt Given that the requirements.txt contains pytest and the app folder has modules with test functions, you should be able to run pytest against the mounted directory: $ docker run --rm -v ${ PWD } /app:/opt/project/app snake pytest /opt/project/ -v # pytest output Because your current working directory is mounted as a volume, the files generated by the commands you run will be available on the host. This means you can run the coverage command in the Docker container and the .coverage file will be available on the host. Given this file, you'll be able to generate the HTML report to view in your host's web browser. Make host environment variables available in a Docker container It is common to use environment variables for storing some settings that Python programs may depend on. Keep in mind that a more robust strategy for storing sensitive information is to use Docker secrets . FROM python:3.7.8-alpine By default, host's environment variables (both permanently stored and temporarily exported) are not available in a Docker container. Given this Python program, import os print ( f 'Token: { os . getenv ( \"SITE_TOKEN\" ) } ' ) you can run it in a Docker container: $ export SITE_TOKEN = 'mytoken' $ docker build -t snake . $ docker run -v ${ PWD } /app:/opt/project/app snake python3 /opt/project/app/main.py # Token: None The -e ( --env ) parameter will let you specify the environment variables you want to propagate into the Docker container. $ export SITE_TOKEN = 'mytoken' $ docker run -e SITE_TOKEN = ${ SITE_TOKEN } -v ${ PWD } /app:/opt/project/app snake \\ python3 /opt/project/app/main.py # Token: mytoken Attach to a running Docker container When running a Python program in a Docker container in debugging mode, it can be useful to be able to pause the program and connect to the container to be able to inspect the file system. A few IDEs such as PyCharm and VSCode provide support for remote Python debugging and will be able to start a Docker container running a Python program and then later tell you its id. This is especially useful when the Python program is expected to produce some files and you would like to inspect them to verify the program produces correct results. If you know the container id, you can attach to it with: $ docker exec -it <container_id> /bin/bash If you don't know the container id, you will need to get it first which can be done with: $ docker ps --filter status = running The CONTAINER ID field will contain the id of the Docker container you will need to attach to. If you have multiple running containers, the one you need is likely to be the first one in the list. Happy containerization!","tags":"python","url":"/docker-for-python-cheat-sheet.html","loc":"/docker-for-python-cheat-sheet.html"},{"title":"Using pyfakefs for unit testing in Python","text":"Overview of unit testing When writing unit tests for programs, it is commonly considered to be a good practice to avoid relying on any part of the system infrastructure such as: network connectivity (you can't get data from a web service) operating system functionality (you can't call grep ) additional software installations (you can't rely on having Microsoft Excel installed) Another suggestion is to avoid making modifications to the files on disk. Testing pieces of code where files may be created or modified often involves patching the functions responsible for writing on disk such as the built-in open function, various os module functions such as os.mkdir and os.makedirs , and pathlib.Path methods such as Path.touch and Path.open . If writing to file system doesn't happen very often, using a few simple patches will suffice. However, for more heavy data-driven programs or programs that are written for any kind of data processing, patching endless number of function calls throughout the code can become rather tedious very soon. Using system temp directory At some point, it may be more efficient to use a more relaxed approach which involves using the tempfile module to create and modify files within the operating system temporary directory which is guaranteed to exist and be writable (at least on POSIX). This approach has some limitations: one wouldn't be able to make changes to files at system paths if this is an essential part of the program functionality unit tests writing on disk will become slower and with many of them can slow down the development-testing iterative cycle running tests in parallel (or using multithreading) can be unreliable as multiple tests may attempt to write/read to/from the very same files at the same time running a test making file system modifications can leave the system in a favourable state for the subsequent tests to be run which can lead to flaky tests Using virtual file system Alternatively, a more robust approach is to not write on disk and instead use a virtual, in-memory file system. For Python, there is a package called pyfakefs that makes it possible. Surprisingly it's not very well known in the Python community and I thought it would be helpful to share the word as I find this package to be indispensable in unit testing of programs which work heavily with files. The package can be used both with unittest and pytest frameworks and under any operating system. Here is a trivial example of writing a unit test for a function that merges content of all files within a given directory into a new file in the same directory. from pathlib import Path from pyfakefs.pytest_plugin import Patcher as FakeFileSystem from utils import merge_files def test_merge_files (): with FakeFileSystem () as _ : dest_dir = Path ( '/opt/data' ) dest_dir . mkdir ( parents = True ) dest_dir . joinpath ( 'file1' ) . write_text ( 'line1 \\n line2 \\n ' ) dest_dir . joinpath ( 'file2' ) . write_text ( 'line3 \\n line4 \\n ' ) merge_files ( source = dest_dir , target = 'result' ) assert dest_dir . joinpath ( 'result' ) . read_text () == 'line1 \\n line2 \\n line3 \\n line4 \\n ' Please refer to the pyfakefs documentation to learn more. Virtual file system caveats A few notes that can help to avoid common pitfalls: make sure not to construct Path objects outside of the patching context (the FakeFileSystem() in the example above) because it will otherwise be pointing to the real file system since the Path class has not been patched yet when using the fake file system for integration tests, keep in mind that you won't be able to use any external tools such as file or cp commands to interact with the fake file system files to verify that you are using the virtual, fake file system in your tests, you can choose to create files in a directory where you won't have modify permissions on your real file system – this will help you identify any cases where pyfakefs support is limited watch closely the permissions the user running the tests have as pyfakefs will operate under the root if run in a Docker container do not use the operating system temporary directory as the fake file system destination directory because pyfakefs doesn't patch the tempfile module Happy faking!","tags":"python","url":"/intro-pyfakefs-python-testing.html","loc":"/intro-pyfakefs-python-testing.html"},{"title":"Brief overview of the reproducible builds concept","text":"Introduction When working with the source code in a project that has multiple build steps (compiling, linking, patching, packaging) when a final \"product\" – a Debian package, an installable application, or an executable with shared libraries – is produced, there are many reasons why it can be useful to be able to get the same binary code (bit-by-bit) from the same source code. If you are able to build your project source code and then re-build it again later (without making any changes to the source code) and the produced artifacts are identical, it is said that your builds are reproducible/deterministic . How can one set up a reproducible build? According to the https://reproducible-builds.org definition: A build is reproducible if given the same source code, build environment and build instructions, any party can recreate bit-by-bit identical copies of all specified artifacts. For a simple project with a small number of movings parts, it may be relatively easy to achieve reproducible builds whereas for a corporate software development project this can be a challenge. There are multiple reasons why the binaries produced by a build operation may differ between builds run from the same source code. There are a few resources that will help you get started: An introduction to deterministic builds with C/C++ provides a gentle introduction to the concept and its importance and benefits Reproducible builds will help you learn more about software development practices around the reproducible builds. Elements of indeterminism Two most common issues are timestamps (when the source code is built) which may be saved into the produced binaries and path information (the location of the source code files on disk) which can also be included into the output binaries. However, many other things can have impact and make two binaries different (they may have the same size, but still be different when doing bit-by-bit comparison). Some of the things you will have control from the build system tools perspective such as compilers and linkers. For instance, you can control the order in which files are being processed as file systems generally do not make any promises that when you iterate the files in a given directory, they will be retrieved in the same order at all times. Other things may be defined in your custom post-processing logic – for instance, the order in which you set certain properties on a binary (such as RPATH patching) can also result in two different binaries. Sample project I have created a GitHub repository with the source code files that have been used in the Conan article An introduction to deterministic builds with C/C++ and it is available at reproducible-builds-example . This example project demonstrates the concept of reproducible builds with a few C++ source files and CMake build steps. A great tool that will help you compare the binaries in your effort to achieve reproducible builds is Diffoscope . It is extremely powerful and has functionality for generating HTML reports showing the difference between two objects you are comparing. This makes it so much easier to see why your binaries are different. Below is a screenshot of the HTML report that shows the difference between two executables. Happy diffing!","tags":"build-systems","url":"/intro-reproducible-builds.html","loc":"/intro-reproducible-builds.html"},{"title":"Using quicktype.io service to create Python interfaces from JSON","text":"Introduction For the last few years I had to write a few simple Python wrappers around a couple of external services. There are many advantages to having a nice Pythonic interface into libraries and tools that are written in other programming languages. It often makes it easier to automate, more pleasant to interact with, and faster to program in general. Bindings and wrappers Some wrappers simply expose the original interfaces without adding anything – these are plain bindings and this is often the case for C++ libraries that have Python bindings such Qt with PyQt . Python code you'd write using plain Python bindings may not feel very Pythonic (due to camelCase ) and because you often have to write programs using other, non-Pythonic, paradigms such as obj.setColor('Red') instead of obj.color = 'Red' . It is, in fact, not uncommon to write Python wrappers around Python bindings for C++ libraries simply because the Python bindings do not make Python developers who use them much more productive. Another group of Python wrapping effort exists around wrapping web services interaction to avoid dealing with cumbersome HTTP requests construction, response processing, and service communication. Likewise, wrapping a CLI tool in Python can be very useful if this is the only way to interact with the underlying software. Working with JSON No matter how you are getting back a JSON response – from a web service or from a CLI tool – you will need to process it to either present the result to the end user or to manage it in some other way. When dealing with JSON data, the built-in json module comes in handy and extracting the information you need out of a JSON object is trivial. You could also take advantage of higher level HTTP communication library such as requests . At the beginning, the code may look something like this: import requests data = requests . get ( 'https://s2k7tnzlhrpw.statuspage.io/api/v2/status.json' ) . json () status = data [ 'status' ][ 'description' ] updated_at = data [ 'page' ][ 'updated_at' ] print ( f \"Status: { status } \\n Updated at: { updated_at } \" ) Output: Status: All Systems Operational Updated at: 2020-08-12T08:08:25.828Z Interacting with the returned JSON objects using only the json module will suffice for smaller scripts and ad-hoc web service interrogation. If you'd like to build a Python wrapper around a large REST interface with many endpoints, however, it may be useful to think about having higher level abstractions for the data entities you deal with. The code snippet above has a number of issues: it relies on having the data elements present when using accessing JSON objects (you could work around it using the .get() method – data.get('status', {}).get('description', 'N/A') but it is still very fragile) as JSON objects keys are represented as strings, it's impossible to run any static type checker (and it has additional complications – refactoring becomes really hard) it makes it hard to reason about the data entities as their data type is not obvious (and you would have to provide a type hint for each JSON object such as status: Dict[str, str] = data['status'] which will become tedious very quickly) Representation of JSON as Python classes To make it easier to interact with JSON objects, they can be used to construct instances of Python classes which are much easier to work with: they provide nice abstraction, they are easy to write unit tests for, and the code that uses them can be inspected with a static analysis tool such as mypy . import requests from typing import Optional from datetime import datetime from dateutil import parser class Page : id : Optional [ str ] name : Optional [ str ] url : Optional [ str ] time_zone : Optional [ str ] updated_at : Optional [ datetime ] def __init__ ( self , id : Optional [ str ], name : Optional [ str ], url : Optional [ str ], time_zone : Optional [ str ], updated_at : Optional [ str ]): self . id = id self . name = name self . url = url self . time_zone = time_zone self . updated_at = parser . parse ( updated_at ) class Status : indicator : Optional [ str ] description : Optional [ str ] def __init__ ( self , indicator : Optional [ str ], description : Optional [ str ]): self . indicator = indicator self . description = description class System : page : Optional [ Page ] status : Optional [ Status ] def __init__ ( self , data ): self . page = Page ( ** data [ 'page' ]) self . status = Status ( ** data [ 'status' ]) data = requests . get ( 'https://s2k7tnzlhrpw.statuspage.io/api/v2/status.json' ) . json () system = System ( data ) status = system . status . description updated_at = system . page . updated_at . strftime ( ' %d /%m/%Y' ) print ( f \"Status: { status } \\n Updated at: { updated_at } \" ) Output: Status: All Systems Operational Updated at: 2020-08-12T08:08:25.828Z Having these classes will solve the issues that the original code snippet had. You can now extend the classes with more fields and add additional logic to any class – the Page class can have a local time zone property or the Status.description can be an instance of the StatusType(Enum) class, for instance. Autogeneration of Python classes from JSON It would be very useful if one could generate Python classes declarations from an API specification file. Swagger tools make it possible to generate an API specification which one could then convert into a collection of Python classes. This approach is very useful but the generated Python classes would be simply data classes without any logic – your fields with the date would be strings, not datetime objects. I think it works best for APIs that change often, during the development when you are iterating on the API design, or when having the raw data classes is sufficient. Another approach is to auto-generate a collection of Python classes from the API specification and extend their initialization logic and to add additional fields/methods as required. This approach has worked well for me and would be particularly useful for any internal tooling when you have control over the API changes. I found the QuickType.io – the service that can convert JSON into typesafe code in many languages including Python – to be really helpful. The classes declared in the snippet above have been generated by quicktype.io from JSON and then modified so that the root class System will have other class instances as its fields. That is, you just have to provide the root JSON object and the root class System will populate all its fields with respective classes as required. For this, a handy Python feature of unpacking keyword arguments with ** is used. This way, the quicktype.io service generates all the boilerplate Python code needed and then some additional modification can be done (e.g. to overload the __repr__ magic method to dump a JSON representation of the class instance). I think you will see the value of using a Python class to represent a JSON object very quickly and with the help of quicktype.io , autogeneration of Python data classes is incredibly easy. Happy automating!","tags":"python","url":"/quicktype-json-class-generation.html","loc":"/quicktype-json-class-generation.html"},{"title":"Building Python extension modules for C++ code with pybind11","text":"Introduction If you ever needed to provide interface to the C/C++ code from your Python modules, you may have used Python extension modules . They are typically created when there is an existing C++ project and it is required to make it accessible via Python bindings. Alternatively, when performance becomes critical, a certain part of the Python project can be written in C/C++ and made accessible to the rest of the Python codebase via some kind of interface. Quite a few large C++ libraries and frameworks have associated Python bindings – they can be used for prototyping or simply to speed up the development as writing a Python program is supposed to take less time than writing an equivalent C++ program. Exposing your library interface with another popular language, such as Python, will also make your project more accessible for programmers who are not very familiar with C++. Refer to excellent RealPython: Python Bindings: Calling C or C++ From Python article to learn more. Python bindings There are quite a few options on how you can make your C++ code accessible from Python. However, I have personally worked only with SWIG and pybind11 so far. For now, let's focus on pybind11 . It's extremely easy to set up on Linux or Windows and you should be able to create a compiled Python extension module ( .so for Linux and .pyd for Windows) very quickly. The pybind11 documentation does provide excellent reference information with a ton of examples. However, those examples often demonstrate features in isolation and I thought it would be useful to share an example of a more complete \"library\" where multiple examples are combined into something that looks like a MVP. Writing C++ code Here is the C++ file, Geometry.cpp , I've written to demonstrate the pybind11 features. It showcases constructing custom Point class instances, finding the distance between them in 2D and 3D space, and overloading C++ comparison operators among a few other things. #include <pybind11/pybind11.h> #include <pybind11/operators.h> #include <string> #include <sstream> #include <iomanip> #include <cmath> namespace py = pybind11 ; using namespace std ; class Point { public : Point ( const double & x , const double & y ) : x ( x ), y ( y ) { z = numeric_limits < double >:: quiet_NaN (); py :: print ( \"Constructing a point with z set to nan\" ); } Point ( const double & x , const double & y , const double & z ) : x ( x ), y ( y ), z ( z ) { py :: print ( \"Constructing a point with z set to a user given value\" ); } double x ; double y ; double z ; string shapeType = \"Point\" ; double distanceTo ( Point point , bool in3D ) { if ( in3D ) { if ( ! isnan ( z ) && ! isnan ( point . z )) { return sqrt ( pow (( point . x - x ), 2 ) + pow (( point . y - y ), 2 ) + pow (( point . z - z ), 2 )); } else { py :: print ( \"Cannot measure distance between points in XY and XYZ space\" ); return numeric_limits < double >:: quiet_NaN (); } } else { return sqrt ( pow (( point . x - x ), 2 ) + pow (( point . y - y ), 2 )); } } bool static areEqual ( Point left , Point right ) { if ( isnan ( left . z ) && isnan ( right . z )) { return left . y == right . y && left . x == right . x ; } else if ( isnan ( left . z ) &#94; isnan ( right . z )) { return false ; } else { return left . y == right . y && left . x == right . x && left . z == right . z ; } } friend bool operator == ( const Point & left , const Point & right ) { return areEqual ( left , right ); } friend bool operator != ( const Point & left , const Point & right ) { return ! areEqual ( left , right ); } bool is3D () const { return ! isnan ( z ); } }; PYBIND11_MODULE ( Geometry , m ) { m . doc () = \"C++ toy geometry library\" ; py :: class_ < Point > ( m , \"Point\" , \"Point shape class implementation\" ) . def ( py :: init < const double & , const double &> (), py :: arg ( \"x\" ), py :: arg ( \"y\" )) . def ( py :: init < const double & , const double & , const double &> (), py :: arg ( \"x\" ), py :: arg ( \"y\" ), py :: arg ( \"z\" )) . def_readonly ( \"x\" , & Point :: x ) . def_readonly ( \"y\" , & Point :: y ) . def_readonly ( \"z\" , & Point :: z ) . def_readonly ( \"shapeType\" , & Point :: shapeType ) . def ( \"distanceTo\" , & Point :: distanceTo , py :: arg ( \"point\" ), py :: arg ( \"in3D\" ) = false , \"Distance to another point\" ) . def ( \"is3D\" , & Point :: is3D , \"Whether a point has a valid z coordinate\" ) . def ( py :: self == py :: self ) . def ( py :: self != py :: self ) . def ( \"__repr__\" , []( const Point & point ) { stringstream xAsString , yAsString , zAsString ; xAsString << std :: setprecision ( 17 ) << point . x ; yAsString << std :: setprecision ( 17 ) << point . y ; zAsString << std :: setprecision ( 17 ) << point . z ; if ( point . z != 0 ) { return \"Point (\" + xAsString . str () + \", \" + yAsString . str () + \", \" + zAsString . str () + \")\" ; } else { return \"Point (\" + xAsString . str () + \", \" + yAsString . str () + \")\" ; } }); } Building a Python extension module Once you have the Geometry.cpp file on disk and pybind11 installed, you should be able to compile the C++ code and link it to the Python headers: $ c++ -O3 -Wall -shared -std = c++11 -fPIC ` python3 -m pybind11 --includes ` Geometry.cpp -o Geometry ` python3-config --extension-suffix ` If you are not very familiar with Bash, command in the backticks in the command above are evaluated by the shell before the main command. The python3 -m pybind11 --includes part is used to get the location of Python header files and the python3-config --extension-suffix part is used to get the suffix for the shared library name – for CPython 3.6 on a 64bit Ubuntu, the Geometry.cpython-36m-x86_64-linux-gnu.so file will be created. Now, once you have the shared library file, it can be imported and used pretty much as if it was a regular Python module. Using a Python extension module Let's see our library in action by running the file python3 use_geometry.py containing the code below: import math from Geometry import Point # runtime dispatch of init constructors print ( Point . __init__ . __doc__ ) # a method signature and its docstring print ( Point . distanceTo . __doc__ ) p1 = Point ( 10 , 20 ) p2 = Point ( 20 , 30 ) p3 = Point ( 20 , 30 ) p4 = Point ( 50 , 60 , 45.67 ) p5 = Point ( 50 , 60 , 45.67 ) assert p1 . distanceTo ( p2 ) == math . sqrt ( 200 ) # check operator overloading works assert p1 != p2 assert p2 == p3 assert not p2 != p3 assert p4 == p5 assert not p4 == p3 assert math . isnan ( p1 . z ) # check distance between 3D points p1 = Point ( 50 , 60 , 45 ) p2 = Point ( 50 , 60 , 75 ) print ( p1 . distanceTo ( p2 , in3D = True )) # check __repr__ print ( p1 ) print ( p2 ) The produced output: __init__(*args, **kwargs) Overloaded function. 1. __init__(self: Geometry.Point, x: float, y: float) -> None 2. __init__(self: Geometry.Point, x: float, y: float, z: float) -> None distanceTo(self: Geometry.Point, point: Geometry.Point, in3D: bool = False) -> float Distance to another point Constructing a point with z set to nan Constructing a point with z set to nan Constructing a point with z set to nan Constructing a point with z set to a user given value Constructing a point with z set to a user given value Constructing a point with z set to a user given value Constructing a point with z set to a user given value Distance between Point (50, 60, 45) and Point (50, 60, 75) is 30.0 Representation of the p1 is \"Point (50, 60, 45)\" Representation of the p2 is \"Point (50, 60, 75)\" This is of course a very trivial example of pybind11 usage, however there have been successful attempts to use pybind11 for binding existing large C++ libraries such as CGAL and Point Cloud Library . See an example of wrapping some of the CGAL functionality with pybind11 and Python bindings for the Point Cloud Library to learn more. Happy binding!","tags":"python","url":"/pybind11-python-bindings.html","loc":"/pybind11-python-bindings.html"},{"title":"What I think a great tech support should look like","text":"Being a software engineer implies that you may be interacting with customers particularly if you are working in a small company. If you are wearing multiple hats or if you are in professional services or tech support, you will likely be contacted by your customers about issues they may experience using your product – a web site, a desktop or a mobile app, or some hardware equipment. Whatever it is, I believe it's best to have a clear plan of actions outlined which you can follow when addressing a customer's issue. No matter how fine-grained your protocol of communication with the customer already is, you can always incorporate some of the ideas I have about how I'd like to work with a customer that needs help. I do understand that it may be difficult or unrealistic to follow the steps below exactly, but this is my vision of a great support. Customer gets in touch Customer reaches out to you because some functionality on the web site of a business system your team built doesn't work as they expect. Pace yourself Do not attempt to provide any solution or ask any questions just yet. If your guess will be accurate – you ask to enable JavaScript in a web browser or to log out and log back in – the customer is less likely to share any details with you because they can now continue working. You, on the other hand, are missing a chance to document the incident to see if it would be possible to prevent it from happening again and to share it with your team members. What was the version of the web browser where the JavaScript is not enabled by default? Did they really have to log out and log back in or a simple refresh of a web page would be enough (you may tweak server-side caching settings)? You may never figure this out and even though the problem is \"solved\" and the customer is happy, in the long run this was a loss. Show empathy No matter what channel of communication is being used – a phone call or an email – the first thing you do is to show some empathy: being an engineer, you know better than anyone how frustrating it can be when a computer doesn't do what you want it to do. Collect information You can start collecting the information you will need to troubleshoot now; don't ask for information you can collect yourself, but sometimes it may still be useful – even if you can SSH into a server to get the version of a software installed, it would still be very useful to ask the customer to tell you the version they see on the web page as an older version may indicate a web page caching issue. You would ideally have a pre-defined template document where you can fill all the information you may need so that you don't have think about it during a phone call. Share information Once you have gathered all the information, make sure to share it with the customer. If on the phone, read it back to them. If it's an email conversation, either share the complete document or provide access to the internal support system (if any) where they would be able to check that the information they've shared with you is accurate. This will help to avoid any misunderstandings and provide traceability as the customer will acknowledge that the information they have provided is correct. Doing troubleshooting Depending on how urgent the request is, you may or may not have time to do some manual production inspection before telling the customer how to fix their problem. If they are in a middle of a presentation to a board of directors, it may be best to tell them how to fix the issue immediately. If it is not time critical, you may want to ask for some time to log in into the production environment to record as much as information as you possibly can. For instance, they told you that they are still able to use the system despite not being logged in. Instead of telling them to log off and log in hoping it will fix the problem (did you know that hope is not a strategy ?), you may want to log in into the server to find out what's going on with your authentication service while the user hasn't left their web browser session (provided you don't do any verbose logging of this type of events already). This issue may indicate some serious problem that is worth investigating further because it may manifest itself again at some point. Update on the progress If the problem requires more time and you will likely need to spend hours if not days working on it, it's best to let the customer know about the progress. They would be able to find it very helpful to see that you are working on their issue and ideally how much time you've spent (a support ticket can be \"in progress\" for 5 days, but the engineer may have been working on it for just 1 hour). Provide a temporary solution if applicable If it's an option, make sure to provide customer with a workaround to let them continue to do their business. If they need to process some files, offer to do it manually for them if possible. If their business operation depends on a feature from their \"basic\" plan that doesn't work and you know that an alternative feature from the \"advanced\" plan would work, upgrade their account for some time while you are troubleshooting. Tell about proposed solution Once you have identified the issue and have been able to solve it, tell the user what was happening and what you have done to solve it. Adjust the language depending on how technical things get as required but don't be afraid to offer them a chance to learn; many customers would find it helpful to understand how the product they use operate under the hood. Ask them to verify that the solution you've implemented works for them (after you have done everything you possibly could to verify this yourself first). Document your findings After you found the resolution to a problem, make sure to document not only what has to be done to fix it, but also what have you attempted to get done which didn't seem to help. For instance, you thought that the problem may be due to a broken database table index and have decided to re-build it. That didn't help and then you think that perhaps recalculating the table statistics may help. You do that now and, yes, the problem is gone. However, documenting that for this problem recalculating the table statistics is necessary may be misleading as re-building the table index may also be required. When you or a colleague of yours will be reading the incident documentation, they will know what have you attempted before finding the solution. Wherever possible, any changes to any environment should be happening via code or a terminal to make it easy to record as making changes in the GUIs are generally known to be very hard to document. A problem that can be solved purely by customers themselves (invalidating the web browser cache or to change some setting within the user interface of the business system itself) is a great candidate to be added into the user documentation. Happy supporting!","tags":"tech-support","url":"/my-version-of-a-great-tech-support.html","loc":"/my-version-of-a-great-tech-support.html"}]};